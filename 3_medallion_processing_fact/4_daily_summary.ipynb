{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ec3ffd0-ad43-4a04-a7d0-385001f296f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Daily Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c284f03-f935-45f9-8f1e-822f00d3dbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, DateType, BooleanType\n",
    "import pyspark.sql.functions as F\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b2fa6d2-ae4a-4b28-bb52-40b1d77a2323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"ecommerce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1da67e33-5416-42bf-811e-4231f9a94dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "days_cutoff = 30\n",
    "source_table_name = \"gld_fact_order_items\"\n",
    "table_name = \"gld_fact_daily_orders_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be81330c-87e4-4d29-b13d-0a0487676f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02\n"
     ]
    }
   ],
   "source": [
    "max_date_row = spark.sql(f\"\"\"\n",
    "    SELECT MAX(transaction_date) AS max_date \n",
    "    FROM {catalog_name}.gold.{source_table_name}\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "max_date = max_date_row['max_date']\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f4b9b7-fd15-467e-9dc6-606ea5442433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(f\"{catalog_name}.gold.{table_name}\"):\n",
    "    where_clause = f\"transaction_date >= date_sub(date('{max_date}'), {days_cutoff})\" # max_date\n",
    "else: \n",
    "    where_clause = \"1=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d4e0f40-a2a3-4132-ba7d-faa7aaaf2ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary_query = f\"\"\"\n",
    "SELECT\n",
    "date_id,\n",
    "unit_price_currency as currency,\n",
    "SUM(quantity) as total_quantity,\n",
    "SUM(gross_amount) as total_gross_amount,\n",
    "SUM(discount_amount) as total_discount_amount,\n",
    "SUM(tax_amount) as total_tax_amount,\n",
    "SUM(net_amount) as total_amount\n",
    "FROM\n",
    "{catalog_name}.gold.{source_table_name}\n",
    "WHERE {where_clause}\n",
    "GROUP BY date_id, currency\n",
    "Order By date_id Desc\n",
    "\"\"\"\n",
    "summary_df = spark.sql(summary_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92bdcdb8-6395-4e05-90f6-e4c0d1ee0e81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------------+------------------+---------------------+----------------+------------+\n| date_id|currency|total_quantity|total_gross_amount|total_discount_amount|total_tax_amount|total_amount|\n+--------+--------+--------------+------------------+---------------------+----------------+------------+\n|20250902|     SGD|           113|           30278.0|                 2580|            3171|     30869.0|\n|20250902|     INR|          1243|       1.8592726E7|              1665699|         1868732| 1.8795759E7|\n|20250902|     CAD|            82|           23052.0|                 2037|            2692|     23707.0|\n|20250902|     USD|           292|           41426.0|                 3140|            4245|     42531.0|\n|20250902|     AUD|            81|           26549.0|                 1302|            2310|     27557.0|\n|20250902|     AED|           164|           92402.0|                10061|            9417|     91758.0|\n|20250902|     GBP|           216|           26220.0|                 1992|            3104|     27332.0|\n+--------+--------+--------------+------------------+---------------------+----------------+------------+\nonly showing top 7 rows\n"
     ]
    }
   ],
   "source": [
    "summary_df.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcdbd647-e1c1-4078-89e9-a299da0571d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n|min_date|max_date|\n+--------+--------+\n|20240101|20250902|\n+--------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_df.select(\n",
    "    F.min(\"date_id\").alias(\"min_date\"),\n",
    "    F.max(\"date_id\").alias(\"max_date\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbd5edaf-4cba-4894-8681-bdee06307169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This code maintains a daily summary Delta table.\n",
    "# - On the first run, it creates the table with all historical data.\n",
    "# - On later runs, it recalculates the last N days (e.g., 30), then merges: updating existing dates and inserting new ones to keep the summary accurate.\n",
    "\n",
    "if not spark.catalog.tableExists(f\"{catalog_name}.gold.{table_name}\"):\n",
    "    summary_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog_name}.gold.{table_name}\")\n",
    "    spark.sql(f\"ALTER TABLE {catalog_name}.gold.{table_name} CLUSTER BY AUTO;\")\n",
    "else:\n",
    "    delta_table = DeltaTable.forName(spark, f\"{catalog_name}.gold.{table_name}\")\n",
    "    delta_table.alias(\"gold_table\").merge(summary_df.alias(\"data_snapshot\"),\"gold_table.date_id = data_snapshot.date_id AND gold_table.currency = data_snapshot.currency\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute() \n",
    "     "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4_daily_summary",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}